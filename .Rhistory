scale = 1        # keep dollars (or set 1e3 for $000)
),
CO = list(                               # C.R.S. § 8-2-113
fips = "08",
yrs  = 2022:2023,
wage = "annual_salary",
cuts = data.table(
start_year = c(2022,   2023),
cutoff     = c(101250, 112500)
),
scale = 1
),
OR = list(                               # ORS § 653.295, **2022+ fixed rule**
fips = "41",
yrs  = 2022:2023,
wage = "annual_salary",
cuts = data.table(
start_year = c(2022,    2023),
cutoff     = c(100533,  112271)
),
scale = 1
),
# ---------- NEW: OREGON 2008-2021  “moving” threshold --------------------
OR_2007 = list(                       # HB 3479 (2007) – rules thru 2021
fips = "41",
yrs  = 2008:2022,
wage = "annual_salary",
cuts = data.table(
start_year = 2008:2022,
cutoff = c(
67500,   # 2008
70000,   # 2009
71200,   # 2010
72000,   # 2011
73000,   # 2012
68300,   # 2013
69400,   # 2014
73900,   # 2015
73300,   # 2016
74700,   # 2017
81400,   # 2018
87900,   # 2019
92100,   # 2020
96900,    # 2021
100533 # 2022
)
),
scale = 1
),
DC = list(                               # D.C. Act 24-483
fips = "11",
yrs  = 2022:2023,
wage = "annual_salary",
cuts = data.table(
start_year = c(2022, 2023),
cutoff     = c(150000, 150000)
),
scale = 1
)
# ---- add more states here as needed ------------------------------------
)
# ---------------------------------------------------------------------------
# 2.  pooled configuration builder  (unchanged) -----------------------------
# ---------------------------------------------------------------------------
cfg_list <- state_cfg[STATES]
if (any(vapply(cfg_list, is.null, logical(1))))
stop("One of the STATE codes in STATES is not in state_cfg.")
cfg <- list(
fips  = vapply(cfg_list, `[[`, "", "fips"),
yrs   = unique(unlist(lapply(cfg_list, `[[`, "yrs"))),
wage  = unique(vapply(cfg_list, `[[`, "",  "wage")),
scale = unique(vapply(cfg_list, `[[`, 1 , "scale"))
)
if (length(cfg$wage ) > 1)
stop("Mixed running-variable definitions (hourly vs annual).")
if (length(cfg$scale) > 1)
stop("Mixed scaling factors – please use comparable states.")
cfg$cuts <- rbindlist(
lapply(cfg_list, \(l) copy(l$cuts)[, fips := l$fips ])
)
# ---------------------------------------------------------------------------
# 3.  filter panel & merge cut-offs  (unchanged) -----------------------------
# ---------------------------------------------------------------------------
panel[ , state_now := sprintf("%02d", as.integer(state_now)) ]
win_start <- min(cfg$yrs)      # 2017 for Illinois
win_end   <- max(cfg$yrs)      # 2021 for Illinois
dat <- panel[
state_now %in% cfg$fips &
start_year >= win_start  &
!is.na(get(cfg$wage))
]
dat <- dat[class_worker_now %in% c(5,6)]
###############################################################################
## helper: “salaried-exempt” flag  – SOC 2-digit codes 11-29 = E-A-P
###############################################################################
is_salaried_exempt <- function(soc_code){
# SIPP SOC codes are usually 6-digit; first two digits give the major group
soc2 <- suppressWarnings(as.integer(substr(sprintf("%06s", soc_code), 1, 2)))
!is.na(soc2) & soc2 >= 11 & soc2 <= 29           # 11–29 are Exec/Admin/Prof
}
dat[ , salaried_exempt := is_salaried_exempt(occupation_now) ]
if (STATE == "OR_2007") {
# OR 2008-2021: salaried-exempt workers are not covered by the law
dat[ , cutoff := fifelse(salaried_exempt, NA_real_, cutoff) ]
}
dat <- merge(
dat,
cfg$cuts,
by.x = c("state_now", "start_year"),
by.y = c("fips",      "start_year"),
all.x = TRUE,
sort  = FALSE
)
dat[ , X := (get(cfg$wage) - cutoff) / cfg$scale ]   # centred / scaled
temp <- copy(dat)        # keeps a clean copy for diagnostics later
# ---------------------------------------------------------------------------
# … everything below (grouping, Laplacians, Fréchet RDD, plots, diagnostics)
#     is identical to what you already have and therefore omitted here.
# ---------------------------------------------------------------------------
###############################################################################
## 3  outcome-specific grouping  (no sprintf, keeps legacy names)            ##
###############################################################################
###############################################################################
library(data.table)
# ---------- helper to grab first L digits (no zero-padding) -----------------
cut_digits <- function(x, L){
x_chr <- as.character(x)
as.integer(substr(x_chr, 1, L))
}
# ---------- tiny look-up tables for pretty labels ---------------------------
get_naics2 <- function(){
url <- "https://raw.githubusercontent.com/afrigeri/naics/master/data/naics2017_2digit.csv"
out <- tryCatch(
fread(url, col.names = c("code","title"), showProgress = FALSE),
error = function(e) NULL
)
if (is.null(out)){                       # offline fallback
out <- data.table(
code  = c("11","21","22","23","31","32","33","42","44","45","48","49",
"51","52","53","54","55","56","61","62","71","72","81","92"),
title = c("Agriculture/Forestry/Fishing",
"Mining/Oil-&-Gas","Utilities","Construction",
"Food/Textile Mfg","Paper/Print/Leather Mfg","Other Mfg",
"Wholesale Trade","Retail Trade (44)","Retail Trade (45)",
"Transport/Warehouse (48)","Transport/Warehouse (49)",
"Information","Finance & Insurance","Real-Estate & Rental",
"Professional Services","Mgmt of Companies",
"Administrative & Waste","Educational Services",
"Health Care & Social Assist.","Arts/Entertainment/Rec",
"Accommodation & Food","Other Private Services",
"Public Administration")
)
}
out[]
}
get_soc2 <- function(){
url <- "https://raw.githubusercontent.com/bls-soc/2018-SOC/master/csv/2018_SOC_Major_Groups.csv"
out <- tryCatch(
fread(url, col.names = c("code","title"), showProgress = FALSE),
error = function(e) NULL
)
if (is.null(out)){                       # offline fallback
out <- data.table(
code  = c("11","13","15","17","19","21","23","25","27","29","31","33",
"35","37","39","41","43","45","47","49","51","53","55"),
title = c("Management","Business & Financial","Computer & Math",
"Architecture & Engineering","Life/Phys/Soc Science",
"Community & Social Service","Legal","Education/Training",
"Arts/Entertainment/Media","Healthcare Practitioners",
"Healthcare Support","Protective Service",
"Food Prep & Serving","Building/Grounds Cleaning",
"Personal Care & Service","Sales","Office & Admin Support",
"Farming/Fishing/Forestry","Construction & Extraction",
"Install/Maint/Repair","Production",
"Transportation & Material Move","Military Specific")
)
}
out[]
}
.naics2_tbl <- get_naics2()
.soc2_tbl   <- get_soc2()
pretty_lab <- function(code_vec, table = c("naics","soc")){
table <- match.arg(table)
key   <- as.character(code_vec)
if (table == "naics"){
out <- .naics2_tbl[match(key, code), title]
} else {
out <- .soc2_tbl  [match(key, code), title]
}
ifelse(is.na(out), key, out)
}
# ---------- build groups ----------------------------------------------------
if (OUTCOME == "occ4") {
dat <- dat[!is.na(occupation_now) & !is.na(occupation_next)]
if (OCC_LEVEL == 1L){                       # legacy 4 buckets
grp_fun <- function(code){
g1 <- substr(as.character(code), 1, 1)
fifelse(g1 %in% c("0","1"), 1L,
fifelse(g1 %in% c("2","3","4"), 2L,
fifelse(g1 %in% c("5","6"), 3L, 4L)))
}
labs <- c("Mgmt/Prof","Service+Sales","Agri/Constr","Blue-collar")
} else {
grp_fun <- \(x) cut_digits(x, OCC_LEVEL)
labs <- if (OCC_LEVEL == 2L)
pretty_lab(sort(unique(grp_fun(dat$occupation_now))), "soc")
else sort(unique(grp_fun(dat$occupation_now)))
}
from <- grp_fun(dat$occupation_now)
to   <- grp_fun(dat$occupation_next)
# ---------------------------------------------------------------------------
} else if (OUTCOME == "ind4") {
dat <- dat[!is.na(industry_now) & !is.na(industry_next)]
if (IND_LEVEL == 1L){                       # legacy 4 clusters
grp_fun <- function(code){
d2 <- as.integer(substr(as.character(code), 1, 2))
fifelse(d2 %in% c(11,21,23),            1L,
fifelse(d2 %in% c(31:33,42:49),         2L,
fifelse(d2 %in% c(51:81),               3L, 4L)))
}
labs <- c("Goods/Res/Constr","Mfg+Trade","Priv Serv","Public/Admin")
} else {
grp_fun <- \(x) cut_digits(x, IND_LEVEL)
labs <- if (IND_LEVEL == 2L)
pretty_lab(sort(unique(grp_fun(dat$industry_now))), "naics")
else sort(unique(grp_fun(dat$industry_now)))
}
from <- grp_fun(dat$industry_now)
to   <- grp_fun(dat$industry_next)
# ---------------------------------------------------------------------------
} else if (OUTCOME == "labor") {
grp_fun <- \(s) fifelse(s %in% 1:5,1L,
fifelse(s %in% 6:7,2L,3L))
dat  <- dat[!is.na(emp_status_now) & !is.na(emp_status_next)]
from <- grp_fun(dat$emp_status_now)
to   <- grp_fun(dat$emp_status_next)
labs <- c("Employed","Unemployed","NILF")
# ---------------------------------------------------------------------------
} else if (OUTCOME == "class") {
grp_fun <- \(cw) fifelse(cw %in% c(1,3,4),1L,
fifelse(cw %in% c(5,6),2L,
fifelse(cw == 2,3L,4L)))
dat  <- dat[!is.na(class_worker_now) & !is.na(class_worker_next)]
from <- grp_fun(dat$class_worker_now)
to   <- grp_fun(dat$class_worker_next)
labs <- c("Gov’t emp","Private emp","Military","Self-emp")
} else stop("OUTCOME must be occ4 / ind4 / labor / class")
###############################################################################
# ---------- convert raw codes to contiguous indices (character → index) -----
###############################################################################
valid_code <- function(char_vec, table = c("naics","soc")){
table <- match.arg(table)
if (table == "naics"){
char_vec %in% .naics2_tbl$code
} else {
char_vec %in% .soc2_tbl$code
}
}
if (OUTCOME == "occ4" && OCC_LEVEL == 2L){
# keep all rows; map any unknown SOC 2-digit to "00"
from_chr <- substr(as.character(dat$occupation_now ), 1, 2)
to_chr   <- substr(as.character(dat$occupation_next), 1, 2)
ok <- from_chr %in% .soc2_tbl$code
from_chr[!ok] <- "00"
ok <- to_chr %in% .soc2_tbl$code
to_chr[!ok]   <- "00"
levels_vec <- sort(unique(c(from_chr, to_chr)))
labs       <- pretty_lab(levels_vec, "soc")
labs[labs == "00"] <- "Other / Unclassified"
from <- match(from_chr, levels_vec)   # 1 … K contiguous indices
to   <- match(to_chr,   levels_vec)
K    <- length(levels_vec)
} else if (OUTCOME == "ind4" && IND_LEVEL == 2L){
## ---- keep every row, map unknown 2-digit NAICS to “00” -----------------
from_chr <- substr(as.character(dat$industry_now ), 1, 2)
to_chr   <- substr(as.character(dat$industry_next), 1, 2)
ok <- from_chr %in% .naics2_tbl$code
from_chr[!ok] <- "00"
ok <- to_chr %in% .naics2_tbl$code
to_chr[!ok]   <- "00"
levels_vec <- sort(unique(c(from_chr, to_chr)))
labs       <- pretty_lab(levels_vec, "naics")
labs[labs == "00"] <- "Other / Unclassified"
from <- match(from_chr, levels_vec)      # 1 … K indices
to   <- match(to_chr,   levels_vec)
K    <- length(levels_vec)
} else {                                # legacy buckets or ≥3-digit cuts
from_chr   <- as.character(from)
to_chr     <- as.character(to)
levels_vec <- sort(unique(c(from_chr, to_chr)))
## 'labs' already defined earlier for these cases
}
from <- match(from_chr, levels_vec)     # 1 … K contiguous indices
to   <- match(to_chr,   levels_vec)
K    <- length(levels_vec)
###############################################################################
## 4  build Laplacian list ----------------------------------------------------
###############################################################################
lap_fun <- function(i,j){
A <- matrix(0,K,K); if(i!=j){A[i,j]<-1;A[j,i]<-1}
D <- diag(rowSums(A)); D - A
}
dat[, laplacian := Map(lap_fun, from, to)]
Y_list <- dat$laplacian
X      <- dat$X
optns  <- list(metric="frobenius", W_laplacian_bound=1)
###############################################################################
## 4  build *directed* Laplacian list  (NEW)                                 ##
###############################################################################
build_L_directed <- function(i, j, K){
# directed edge i → j  (exclude self-loops)
A <- matrix(0, K, K)
if (i != j) A[i, j] <- 1
d_out <- rowSums(A)           # out-degree of each node
diag(d_out) - A               # L = D_out − A    (not symmetric)
}
dat[ , laplacian := Map(build_L_directed,
i = from, j = to,
MoreArgs = list(K = K))]
Y_list <- dat$laplacian
X      <- dat$X
optns  <- list(metric="frobenius", W_laplacian_bound=1, network_directed = TRUE)
###############################################################################
## 5  Fréchet local-RD test ---------------------------------------------------
###############################################################################
res <- frechesTest(
Y_obj    = Y_list,
X_scalar = X,
c_val    = 0,
metric_space_type  = "network",
h_frechet          = "CV",
frechet_optns      = optns,
cv_K_folds         = 5,
cv_n_bw_candidates = 10,
verbose            = TRUE
)
cat(sprintf(
"\n== STATES: %s   |   OUTCOME: %s ==\nN = %d  |  h = %.3f  |  T = %.3f  |  p = %.4f\n",
paste(STATES,collapse="+"), OUTCOME, nrow(dat),
res$h_mean_cv_selected, res$Tn, res$p_value))
L_jump <- res$l_hat_plus - res$l_hat_minus
A_jump <- -L_jump; diag(A_jump) <- 0        # adjacency jump
###############################################################################
## 6  heat-map & top-flow tables ---------------------------------------------
###############################################################################
ggplot(reshape2::melt(A_jump, varnames=c("from","to"), value.name="Δ"),
aes(from,to,fill=Δ))+
geom_tile(colour="grey80")+
scale_fill_gradient2(low="#4575b4",mid="white",high="#d73027",midpoint=0)+
coord_equal()+
scale_x_continuous(breaks=1:K, labels=labs)+
scale_y_continuous(breaks=1:K, labels=labs)+
labs(title=sprintf("Δ flows at cut-off  –  %s (%s)", paste(STATES,collapse="+"), OUTCOME),
x="Origin", y="Destination", fill="Δ edge-wt")+
theme_minimal(base_size=13)
dtF <- as.data.table(reshape2::melt(A_jump,
varnames=c("from","to"), value.name="Δ"))[from!=to]
dtF[, `:=`(from_lbl=labs[from], to_lbl=labs[to])]
setorder(dtF, -Δ); cat("\nTop 10 ↑ flows\n")
print(dtF[1:10, .(from_lbl,to_lbl,Δ)], row.names=FALSE)
setorder(dtF,  Δ); cat("\nTop 10 ↓ flows\n")
print(dtF[1:10, .(from_lbl,to_lbl,Δ)], row.names=FALSE)
# ## ---------------------------------------------------------------------------
# ## 6  Robust placebo / permutation test  -------------------------------------
# ## ---------------------------------------------------------------------------
# run_placebo_perm <- function(
#     Y_list, X,                             # data
#     c_val_true, h_opt,                    # true cut-off & bandwidth
#     n_perm          = 200,                # how many placebos do you want?
#     min_pts_side    = 5L,                # inside the window!
#     donut_mult      = 1,                # exclude |X| < donut_mult·h_opt
#     max_h_mult      = 4,                  # try larger windows up to this × h_opt
#     seed            = 1L,
#     fre_opts        = list(metric = "frobenius", W_laplacian_bound = 1)
# ){
#   set.seed(seed)
#
#   ## ---------- 1. admissible grid of cut-offs -------------------------------
#   excl  <- donut_mult * h_opt
#   grid  <- sort( unique( X[ abs(X) > excl ] ) )
#
#   enough <- function(c0, h, m = min_pts_side){
#     w <- abs(X - c0) <= h
#     sum(w & X <  c0) >= m && sum(w & X >= c0) >= m
#   }
#   grid  <- grid[ vapply(grid, enough, logical(1), h = h_opt) ]
#   if (!length(grid))
#     stop("No placebo cut-offs have ≥ ", min_pts_side,
#          " pts/side inside ±h_opt.  Try smaller ‘min_pts_side’ or",
#          " a larger ‘donut_mult’.")
#
#   if (length(grid) > n_perm) grid <- sample(grid, n_perm)
#
#   ## ---------- 2. run permutations -----------------------------------------
#   resMat <- matrix(NA_real_, nrow = length(grid), ncol = 2,
#                    dimnames = list(NULL, c("p","dF")))
#
#   for (k in seq_along(grid)){
#     c0 <- grid[k]
#     success <- FALSE
#     h_mult  <- 1          # start with h_opt
#     while(!success && h_mult <= max_h_mult){
#       h_use <- h_mult * h_opt
#       if (!enough(c0, h_use)){
#         h_mult <- h_mult * 1.5           # enlarge and try again
#         next
#       }
#       tmp <- tryCatch(
#         {
#           r <- frechesTest(
#             Y_obj             = Y_list,
#             X_scalar          = X,
#             c_val             = c0,
#             h_frechet         = "CV",
#             metric_space_type = "network",
#             frechet_optns     = fre_opts,
#             verbose           = FALSE
#           )
#           dF <- sqrt(sum((r$l_hat_plus - r$l_hat_minus)^2))
#           c(p = r$p_value, dF = dF)
#         },
#         error = function(e) NA_real_
#       )
#       if (is.numeric(tmp[1])) {          # worked
#         resMat[k,] <- tmp
#         success    <- TRUE
#       } else {
#         h_mult <- h_mult * 1.5           # enlarge window and retry
#       }
#     }
#   }
#
#   resMat <- resMat[ complete.cases(resMat) , , drop = FALSE ]
#   attr(resMat, "placebos") <- grid[ complete.cases(resMat) ]
#   resMat
# }
#
# ## ---------- run it ---------------------------------------------------------
# ok          <- !is.na(dat$X)
# dat         <- dat[ ok ]                 # drop those rows
# Y_clean     <- dat$laplacian
# X_clean     <- dat$X
# h_opt_clean <- res$h_mean_cv_selected    # fine – bandwidth was computed on the same dat
#
# perm <- run_placebo_perm(
#   Y_list      = Y_clean,
#   X           = X_clean,
#   c_val_true  = 0,
#   h_opt       = h_opt_clean,
#   n_perm      = 500,
#   min_pts_side= 5,
#   donut_mult  = 1
# )
#
# p_perm <- perm[,"p"];  d_perm <- perm[,"dF"]
# d_true <- sqrt(sum((res$l_hat_plus - res$l_hat_minus)^2))
# p_true <- res$p_value
#
# cat(sprintf(
#   "\nPermutation p-value (||L⁺ − L⁻||_F) = %.4f   (B = %d)\n",
#   mean(d_perm >= d_true), length(d_perm) ))
# cat(sprintf(
#   "Permutation p-value (test-statistic)   = %.4f   (B = %d)\n",
#   mean(p_perm <= p_true), length(p_perm) ))
###############################################################################
#  RD diagnostics : McCrary density + covariate balance tests                #
###############################################################################
library(rddensity)   # McCrary (2020) implementation
library(rdrobust)    # covariate continuity tests
library(data.table)
# ## ---- 1.  choose sample & running variable ---------------------------------
# IL_FIPS <- "17"
# dat_il <- panel_final[
#   state_now == IL_FIPS &
#     start_year %between% c(2017L, 2022L) &           # pre & post low-wage law
#     !is.na(hourly_wage)
# ]
#
# dat_il <
#
# dat_il[, X := hourly_wage - 13]    # running variable centred at cutoff = 0
dat_il <- copy(temp)
## ---- 2.  McCrary density test ---------------------------------------------
dens_out <- rddensity(dat_il$X, c = 0, massPoints=TRUE)
cat("\n================  McCrary density test (Illinois)  ================\n")
print(summary(dens_out))
rddisttest(RV = dat_il$X, C=0, K=0.5)
#
# # plot histogram of X with vertical line at 13
# hist(dat_il$X, breaks=200, main="Histogram of X", xlab="X")
# abline(v=0, col="red", lwd=2)
## ---- 3.  Covariate continuity tests ---------------------------------------
# TODO: maybe try weights
dat_il$female <- as.numeric(dat_il$sex == 2)
covariates <- c("age_start","female","educ_level", "wfh_any_now", "wfh_any_next")
balance_tbl <- rbindlist(lapply(covariates, \(v){
w <- !is.na(dat_il[[v]])
est <- rdrobust(y = dat_il[[v]][w],
x = dat_il$X[w],
c = 0,
p = 1)                # local linear
data.table(
covariate = v,
tau_hat   = est$coef[1],
se_tau    = est$se[1],
p_value   = est$pv[[3]]
)
}))
cat("\n================  RD covariate balance (Illinois)  ================\n")
print(balance_tbl, digits = 3)
p.adjust(balance_tbl$p_value)
res$p_value
